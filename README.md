# Abstract

Vision is one of the most essential human senses, playing a crucial role in how we perceive and
interact with our environment. Recognizing the profound impact of visual impairment, this
project addresses the challenges faced by blind and visually impaired (BVI) individuals in
navigating and understanding their surroundings. Motivated by the need for more accessible
and context-aware assistive technologies, we developed Audieyes, a visionary application
leveraging advanced AI to provide real-time scene descriptions and interactive assistance. The
primary objectives were to enhance the autonomy and quality of life for BVI users through
accurate, context-sensitive environmental descriptions, and to ensure seamless integration of
the technology into usersâ€™ daily lives. Key challenges included ensuring real-time performance,
maintaining a low price of entry, and providing culturally relevant assistance, particularly for
Moroccan users. Our methodology integrated state-of-the-art Large Language Models (LLMs),
specifically GPT-4o-mini, chosen for its superior performance in multimodal tasks and costeffectiveness. 
We implemented a robust DevOps pipeline with continuous integration and
deployment (CI/CD) practices for rapid development and reliable updates, alongside Large
Language Model Operations (LLMOps) practices to ensure security, compliance, performance
optimization, and effective user feedback analysis. The system architecture is designed for fault
tolerance and scalability, utilizing microservices, cloud integration with multi-region
deployment, and edge computing. Initial user trials with BVI individuals in Morocco yielded
promising results: Audieyes achieved a 96% user satisfaction rate, with participants reporting
significant improvements in daily navigation and environmental awareness. Users particularly
appreciated the culturally relevant descriptions, with 92% finding them highly contextual and
useful. The application's response time averaged 3.5 seconds, meeting our real-time
performance goals. In terms of technical performance, the system demonstrated a 97% accuracy
rate in classifying objects within images using categories such as Tajin, Msamen, Riad, souk,
and Caftan across various real-world scenarios. Additionally, the system achieved a BLEU-4
score of 40.12% for generating accurate and contextually appropriate descriptions.
Furthermore, 89% of users reported feeling more independent in their daily activities after using
Audieyes for one month. These encouraging outcomes suggest that Audieyes has successfully
addressed critical needs in the BVI community, potentially revolutionizing assistive technology
in Morocco and beyond.
